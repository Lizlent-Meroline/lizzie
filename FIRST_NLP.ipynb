{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wgnzhggS_vTv"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66pjDIYnAgKB",
        "outputId": "fb13ceaf-c9ac-4c8a-a07e-b96a128ebb18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural Language Processing with Python provides a practical introduction to programming for language processing. Written by the creators of NLTK, it guides the reader through the fundamentals of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure, and more. The online version of the book has been been updated for Python 3 and NLTK 3. (The original Python 2 version is still available at https://www.nltk.org/book_1ed.)\""
      ],
      "metadata": {
        "id": "4LpEwP7tBEpI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "tokens = word_tokenize(text.lower())"
      ],
      "metadata": {
        "id": "S-xj9BusBmT9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]"
      ],
      "metadata": {
        "id": "TQxlGNk7CQM_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Frequency of words\n",
        "word_freq = Counter(filtered_tokens)"
      ],
      "metadata": {
        "id": "xg8guhuCD0gR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokens:\", filtered_tokens)\n",
        "print(\"Word Frequencies:\", word_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu7eMRGlFFqr",
        "outputId": "f000ea6f-66e6-41ff-b5d8-3e12dfe97795"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['natural', 'language', 'processing', 'python', 'provides', 'practical', 'introduction', 'programming', 'language', 'processing', 'written', 'creators', 'nltk', 'guides', 'reader', 'fundamentals', 'writing', 'python', 'programs', 'working', 'corpora', 'categorizing', 'text', 'analyzing', 'linguistic', 'structure', 'online', 'version', 'book', 'updated', 'python', '3', 'nltk', '3', 'original', 'python', '2', 'version', 'still', 'available', 'https']\n",
            "Word Frequencies: Counter({'python': 4, 'language': 2, 'processing': 2, 'nltk': 2, 'version': 2, '3': 2, 'natural': 1, 'provides': 1, 'practical': 1, 'introduction': 1, 'programming': 1, 'written': 1, 'creators': 1, 'guides': 1, 'reader': 1, 'fundamentals': 1, 'writing': 1, 'programs': 1, 'working': 1, 'corpora': 1, 'categorizing': 1, 'text': 1, 'analyzing': 1, 'linguistic': 1, 'structure': 1, 'online': 1, 'book': 1, 'updated': 1, 'original': 1, '2': 1, 'still': 1, 'available': 1, 'https': 1})\n"
          ]
        }
      ]
    }
  ]
}